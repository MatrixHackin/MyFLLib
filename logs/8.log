==================================================
device = cuda
device_id = 0
prev = 0
times = 1
global_rounds = 50
eval_gap = 1
batch_size = 10
local_epochs = 1
local_learning_rate = 3e-05
learning_rate_decay = True
learning_rate_decay_gamma = 0.99
auto_break = False
top_cnt = 100
goal = test
save_folder_name = items
model = CLIPWithAdapter
num_classes = 6
algorithm = FedAvg
dataset = DRnpz
data_root = /data/yuxiangyang/lhm/FL/data
num_clients = 5
client_drop_rate = 0.0
random_join_ratio = False
join_ratio = 1.0
num_new_clients = 0
fine_tuning_epoch_new = 0
train_slow_rate = 0.0
send_slow_rate = 0.0
time_threthold = 10000
dlg_eval = False
dlg_gap = 100
batch_num_per_client = 2
==================================================

============= Running time: 0th =============
Creating server and clients ...
CLIP model ViT-B/32 loaded
preprocess: Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=warn)
    CenterCrop(size=(224, 224))
    <function _convert_image_to_rgb at 0x7f8e35dfdb20>
    ToTensor()
    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))
)
CLIPWithAdapter(
  (clip_model): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (image_adapter1): ImageAdapter(
    (attention): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
    )
    (mlp): Sequential(
      (0): Linear(in_features=768, out_features=192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=192, out_features=768, bias=True)
    )
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (image_adapter2): ImageAdapter(
    (attention): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
    )
    (mlp): Sequential(
      (0): Linear(in_features=768, out_features=192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=192, out_features=768, bias=True)
    )
    (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (text_adapter): TextAdapter(
    (model): Sequential(
      (0): Linear(in_features=512, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=512, bias=True)
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)

Join ratio / total clients: 1.0 / 5
Finished creating server and clients.

-------------Round number: 0-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 1.1322
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.8569
Std Test Accurancy: 0.1226
Std Test AUC: 0.0594
------------------------- time cost ------------------------- 498.68286991119385

-------------Round number: 1-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8901
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.8990
Std Test Accurancy: 0.1226
Std Test AUC: 0.0542
------------------------- time cost ------------------------- 479.7281539440155

-------------Round number: 2-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8795
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9013
Std Test Accurancy: 0.1226
Std Test AUC: 0.0538
------------------------- time cost ------------------------- 522.466413974762

-------------Round number: 3-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8769
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9033
Std Test Accurancy: 0.1226
Std Test AUC: 0.0543
------------------------- time cost ------------------------- 530.4940648078918

-------------Round number: 4-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8758
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9017
Std Test Accurancy: 0.1226
Std Test AUC: 0.0540
------------------------- time cost ------------------------- 520.1484389305115

-------------Round number: 5-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8783
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.8995
Std Test Accurancy: 0.1226
Std Test AUC: 0.0530
------------------------- time cost ------------------------- 521.606921672821

-------------Round number: 6-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8809
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.8983
Std Test Accurancy: 0.1226
Std Test AUC: 0.0527
------------------------- time cost ------------------------- 567.580991268158

-------------Round number: 7-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8717
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9032
Std Test Accurancy: 0.1226
Std Test AUC: 0.0540
------------------------- time cost ------------------------- 547.7055993080139

-------------Round number: 8-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8717
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9031
Std Test Accurancy: 0.1226
Std Test AUC: 0.0539
------------------------- time cost ------------------------- 557.7173762321472

-------------Round number: 9-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8721
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9032
Std Test Accurancy: 0.1226
Std Test AUC: 0.0541
------------------------- time cost ------------------------- 558.7566573619843

-------------Round number: 10-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8715
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9041
Std Test Accurancy: 0.1226
Std Test AUC: 0.0544
------------------------- time cost ------------------------- 553.734121799469

-------------Round number: 11-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8710
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9023
Std Test Accurancy: 0.1226
Std Test AUC: 0.0539
------------------------- time cost ------------------------- 552.4659824371338

-------------Round number: 12-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8698
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9030
Std Test Accurancy: 0.1226
Std Test AUC: 0.0540
------------------------- time cost ------------------------- 553.808934211731

-------------Round number: 13-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8697
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9033
Std Test Accurancy: 0.1226
Std Test AUC: 0.0542
------------------------- time cost ------------------------- 553.6405072212219

-------------Round number: 14-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8693
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9034
Std Test Accurancy: 0.1226
Std Test AUC: 0.0542
------------------------- time cost ------------------------- 561.6494081020355

-------------Round number: 15-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8699
Averaged Test Accurancy: 0.6862
Averaged Test AUC: 0.9023
Std Test Accurancy: 0.1226
Std Test AUC: 0.0540
------------------------- time cost ------------------------- 552.3896570205688

-------------Round number: 16-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8695
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9025
Std Test Accurancy: 0.1226
Std Test AUC: 0.0540
------------------------- time cost ------------------------- 557.0466892719269

-------------Round number: 17-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8689
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9046
Std Test Accurancy: 0.1226
Std Test AUC: 0.0544
------------------------- time cost ------------------------- 553.4638018608093

-------------Round number: 18-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8686
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9047
Std Test Accurancy: 0.1226
Std Test AUC: 0.0544
------------------------- time cost ------------------------- 509.3476610183716

-------------Round number: 19-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8681
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9039
Std Test Accurancy: 0.1226
Std Test AUC: 0.0541
------------------------- time cost ------------------------- 477.7740693092346

-------------Round number: 20-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8678
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9038
Std Test Accurancy: 0.1226
Std Test AUC: 0.0541
------------------------- time cost ------------------------- 467.5457429885864

-------------Round number: 21-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8681
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9040
Std Test Accurancy: 0.1226
Std Test AUC: 0.0541
------------------------- time cost ------------------------- 470.6158039569855

-------------Round number: 22-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8689
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9046
Std Test Accurancy: 0.1226
Std Test AUC: 0.0543
------------------------- time cost ------------------------- 465.1559956073761

-------------Round number: 23-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8674
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9033
Std Test Accurancy: 0.1226
Std Test AUC: 0.0540
------------------------- time cost ------------------------- 460.9061291217804

-------------Round number: 24-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8680
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9040
Std Test Accurancy: 0.1226
Std Test AUC: 0.0541
------------------------- time cost ------------------------- 462.3763093948364

-------------Round number: 25-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8670
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9037
Std Test Accurancy: 0.1226
Std Test AUC: 0.0541
------------------------- time cost ------------------------- 463.6677408218384

-------------Round number: 26-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8676
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9035
Std Test Accurancy: 0.1226
Std Test AUC: 0.0541
------------------------- time cost ------------------------- 456.7365069389343

-------------Round number: 27-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8669
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9035
Std Test Accurancy: 0.1226
Std Test AUC: 0.0540
------------------------- time cost ------------------------- 456.4258472919464

-------------Round number: 28-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8677
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9043
Std Test Accurancy: 0.1226
Std Test AUC: 0.0542
------------------------- time cost ------------------------- 458.5496344566345

-------------Round number: 29-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8664
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9037
Std Test Accurancy: 0.1226
Std Test AUC: 0.0541
------------------------- time cost ------------------------- 455.3201627731323

-------------Round number: 30-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8664
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9041
Std Test Accurancy: 0.1226
Std Test AUC: 0.0542
------------------------- time cost ------------------------- 466.09755063056946

-------------Round number: 31-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8665
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9049
Std Test Accurancy: 0.1226
Std Test AUC: 0.0544
------------------------- time cost ------------------------- 463.11033725738525

-------------Round number: 32-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8659
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9045
Std Test Accurancy: 0.1226
Std Test AUC: 0.0543
------------------------- time cost ------------------------- 468.77615118026733

-------------Round number: 33-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8661
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9050
Std Test Accurancy: 0.1226
Std Test AUC: 0.0544
------------------------- time cost ------------------------- 468.10821986198425

-------------Round number: 34-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8658
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9048
Std Test Accurancy: 0.1226
Std Test AUC: 0.0544
------------------------- time cost ------------------------- 464.09075450897217

-------------Round number: 35-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8654
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9047
Std Test Accurancy: 0.1226
Std Test AUC: 0.0544
------------------------- time cost ------------------------- 468.8341748714447

-------------Round number: 36-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8680
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9061
Std Test Accurancy: 0.1226
Std Test AUC: 0.0548
------------------------- time cost ------------------------- 468.39243483543396

-------------Round number: 37-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8678
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9061
Std Test Accurancy: 0.1226
Std Test AUC: 0.0548
------------------------- time cost ------------------------- 471.0561718940735

-------------Round number: 38-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8653
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9054
Std Test Accurancy: 0.1226
Std Test AUC: 0.0546
------------------------- time cost ------------------------- 463.92545914649963

-------------Round number: 39-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8654
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9050
Std Test Accurancy: 0.1226
Std Test AUC: 0.0545
------------------------- time cost ------------------------- 469.2729094028473

-------------Round number: 40-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8657
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9058
Std Test Accurancy: 0.1226
Std Test AUC: 0.0548
------------------------- time cost ------------------------- 460.5145990848541

-------------Round number: 41-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8652
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9056
Std Test Accurancy: 0.1226
Std Test AUC: 0.0547
------------------------- time cost ------------------------- 455.7472412586212

-------------Round number: 42-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8660
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9060
Std Test Accurancy: 0.1226
Std Test AUC: 0.0549
------------------------- time cost ------------------------- 470.9446499347687

-------------Round number: 43-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8665
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9063
Std Test Accurancy: 0.1226
Std Test AUC: 0.0550
------------------------- time cost ------------------------- 466.7868723869324

-------------Round number: 44-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8657
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9054
Std Test Accurancy: 0.1226
Std Test AUC: 0.0548
------------------------- time cost ------------------------- 468.62407994270325

-------------Round number: 45-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8657
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9060
Std Test Accurancy: 0.1226
Std Test AUC: 0.0549
------------------------- time cost ------------------------- 468.4970951080322

-------------Round number: 46-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8654
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9050
Std Test Accurancy: 0.1226
Std Test AUC: 0.0547
------------------------- time cost ------------------------- 456.2380073070526

-------------Round number: 47-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8657
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9059
Std Test Accurancy: 0.1226
Std Test AUC: 0.0550
------------------------- time cost ------------------------- 467.56874918937683

-------------Round number: 48-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8656
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9057
Std Test Accurancy: 0.1226
Std Test AUC: 0.0549
------------------------- time cost ------------------------- 464.7915313243866

-------------Round number: 49-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8675
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9065
Std Test Accurancy: 0.1226
Std Test AUC: 0.0552
------------------------- time cost ------------------------- 465.9652111530304

-------------Round number: 50-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8654
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9056
Std Test Accurancy: 0.1226
Std Test AUC: 0.0549
------------------------- time cost ------------------------- 464.62887930870056

Best accuracy.
0.6861648016276704

Average time cost per round.
492.6159280538559
File path: ../results/DRnpz_FedAvg_test_0.h5

Average time cost: 25177.57s.
Length:  51
std for best accurancy: 0.0
mean for best accurancy: 0.6861648016276704
All done!

Storage on cuda:0
-------------------------------------------------------------------------------
Total Tensors: 1156436273 	Used Memory: 2.43G
The allocated memory on cuda:0: 2.51G
Memory differs due to the matrix alignment or invisible gradient buffer tensors
-------------------------------------------------------------------------------

Storage on cpu
-------------------------------------------------------------------------------
Total Tensors: 223556137 	Used Memory: 426.42M
-------------------------------------------------------------------------------
