==================================================
device = cuda
device_id = 2
prev = 0
times = 1
global_rounds = 50
eval_gap = 1
batch_size = 10
local_epochs = 1
local_learning_rate = 0.05
learning_rate_decay = False
learning_rate_decay_gamma = 0.99
auto_break = False
top_cnt = 100
goal = test
save_folder_name = items
model = CLIPWithAdapter
num_classes = 6
algorithm = FedAvg
dataset = DRnpz
data_root = /data/yuxiangyang/lhm/FL/data/npz
num_clients = 5
client_drop_rate = 0.0
random_join_ratio = False
join_ratio = 1.0
num_new_clients = 0
fine_tuning_epoch_new = 0
train_slow_rate = 0.0
send_slow_rate = 0.0
time_threthold = 10000
dlg_eval = False
dlg_gap = 100
batch_num_per_client = 2
==================================================

============= Running time: 0th =============
Creating server and clients ...
CLIP model ViT-B/32 loaded
preprocess: Compose(
    Resize(size=224, interpolation=bicubic, max_size=None, antialias=warn)
    CenterCrop(size=(224, 224))
    <function _convert_image_to_rgb at 0x7fa96f429a80>
    ToTensor()
    Normalize(mean=(0.48145466, 0.4578275, 0.40821073), std=(0.26862954, 0.26130258, 0.27577711))
)
CLIPWithAdapter(
  (clip_model): CLIP(
    (visual): VisionTransformer(
      (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)
      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (transformer): Transformer(
        (resblocks): Sequential(
          (0): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (1): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (2): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (3): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (4): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (5): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (6): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (7): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (8): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (9): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (10): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
          (11): ResidualAttentionBlock(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (mlp): Sequential(
              (c_fc): Linear(in_features=768, out_features=3072, bias=True)
              (gelu): QuickGELU()
              (c_proj): Linear(in_features=3072, out_features=768, bias=True)
            )
            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (transformer): Transformer(
      (resblocks): Sequential(
        (0): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (1): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (2): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (3): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (4): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (5): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (6): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (7): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (8): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (9): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (10): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (11): ResidualAttentionBlock(
          (attn): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
          )
          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
          (mlp): Sequential(
            (c_fc): Linear(in_features=512, out_features=2048, bias=True)
            (gelu): QuickGELU()
            (c_proj): Linear(in_features=2048, out_features=512, bias=True)
          )
          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (token_embedding): Embedding(49408, 512)
    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
  (image_adapter1): ImageAdapter(
    (model): Sequential(
      (0): Linear(in_features=768, out_features=192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=192, out_features=768, bias=True)
    )
    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (image_adapter2): ImageAdapter(
    (model): Sequential(
      (0): Linear(in_features=768, out_features=192, bias=True)
      (1): GELU(approximate='none')
      (2): Linear(in_features=192, out_features=768, bias=True)
    )
    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (text_adapter): TextAdapter(
    (model): Sequential(
      (0): Linear(in_features=512, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=512, bias=True)
    )
    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  )
)

Join ratio / total clients: 1.0 / 5
Finished creating server and clients.

-------------Round number: 0-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 1.8845
Averaged Test Accurancy: 0.0700
Averaged Test AUC: 0.4708
Std Test Accurancy: 0.0343
Std Test AUC: 0.0632
------------------------- time cost ------------------------- 550.7313475608826

-------------Round number: 1-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.9070
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9128
Std Test Accurancy: 0.1226
Std Test AUC: 0.0556
------------------------- time cost ------------------------- 535.7243189811707

-------------Round number: 2-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.9015
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9160
Std Test Accurancy: 0.1226
Std Test AUC: 0.0578
------------------------- time cost ------------------------- 541.6264526844025

-------------Round number: 3-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8664
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9190
Std Test Accurancy: 0.1226
Std Test AUC: 0.0607
------------------------- time cost ------------------------- 559.5414595603943

-------------Round number: 4-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8641
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9156
Std Test Accurancy: 0.1226
Std Test AUC: 0.0593
------------------------- time cost ------------------------- 554.0429656505585

-------------Round number: 5-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8674
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9147
Std Test Accurancy: 0.1226
Std Test AUC: 0.0588
------------------------- time cost ------------------------- 556.7885186672211

-------------Round number: 6-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8594
Averaged Test Accurancy: 0.6861
Averaged Test AUC: 0.9115
Std Test Accurancy: 0.1223
Std Test AUC: 0.0583
------------------------- time cost ------------------------- 553.1937162876129

-------------Round number: 7-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8536
Averaged Test Accurancy: 0.6867
Averaged Test AUC: 0.9100
Std Test Accurancy: 0.1225
Std Test AUC: 0.0578
------------------------- time cost ------------------------- 558.5002143383026

-------------Round number: 8-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8525
Averaged Test Accurancy: 0.6863
Averaged Test AUC: 0.9078
Std Test Accurancy: 0.1224
Std Test AUC: 0.0560
------------------------- time cost ------------------------- 554.7277328968048

-------------Round number: 9-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8541
Averaged Test Accurancy: 0.6864
Averaged Test AUC: 0.9082
Std Test Accurancy: 0.1223
Std Test AUC: 0.0563
------------------------- time cost ------------------------- 555.8549883365631

-------------Round number: 10-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8450
Averaged Test Accurancy: 0.6869
Averaged Test AUC: 0.9007
Std Test Accurancy: 0.1227
Std Test AUC: 0.0554
------------------------- time cost ------------------------- 543.8938217163086

-------------Round number: 11-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8362
Averaged Test Accurancy: 0.6850
Averaged Test AUC: 0.8923
Std Test Accurancy: 0.1221
Std Test AUC: 0.0524
------------------------- time cost ------------------------- 539.75128865242

-------------Round number: 12-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8344
Averaged Test Accurancy: 0.6886
Averaged Test AUC: 0.8921
Std Test Accurancy: 0.1235
Std Test AUC: 0.0531
------------------------- time cost ------------------------- 559.5457475185394

-------------Round number: 13-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8311
Averaged Test Accurancy: 0.6798
Averaged Test AUC: 0.8879
Std Test Accurancy: 0.1180
Std Test AUC: 0.0494
------------------------- time cost ------------------------- 563.2235126495361

-------------Round number: 14-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8353
Averaged Test Accurancy: 0.6864
Averaged Test AUC: 0.8969
Std Test Accurancy: 0.1226
Std Test AUC: 0.0545
------------------------- time cost ------------------------- 553.5364263057709

-------------Round number: 15-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8304
Averaged Test Accurancy: 0.6860
Averaged Test AUC: 0.8889
Std Test Accurancy: 0.1222
Std Test AUC: 0.0507
------------------------- time cost ------------------------- 554.3767492771149

-------------Round number: 16-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8186
Averaged Test Accurancy: 0.6865
Averaged Test AUC: 0.8882
Std Test Accurancy: 0.1220
Std Test AUC: 0.0506
------------------------- time cost ------------------------- 556.308342218399

-------------Round number: 17-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8316
Averaged Test Accurancy: 0.6852
Averaged Test AUC: 0.8897
Std Test Accurancy: 0.1217
Std Test AUC: 0.0512
------------------------- time cost ------------------------- 553.9828357696533

-------------Round number: 18-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8120
Averaged Test Accurancy: 0.6849
Averaged Test AUC: 0.8934
Std Test Accurancy: 0.1207
Std Test AUC: 0.0531
------------------------- time cost ------------------------- 517.4173476696014

-------------Round number: 19-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8068
Averaged Test Accurancy: 0.6851
Averaged Test AUC: 0.8901
Std Test Accurancy: 0.1209
Std Test AUC: 0.0511
------------------------- time cost ------------------------- 514.581042766571

-------------Round number: 20-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.8058
Averaged Test Accurancy: 0.6757
Averaged Test AUC: 0.8887
Std Test Accurancy: 0.1195
Std Test AUC: 0.0478
------------------------- time cost ------------------------- 514.6518204212189

-------------Round number: 21-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7952
Averaged Test Accurancy: 0.6803
Averaged Test AUC: 0.8874
Std Test Accurancy: 0.1169
Std Test AUC: 0.0505
------------------------- time cost ------------------------- 516.6907484531403

-------------Round number: 22-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7988
Averaged Test Accurancy: 0.6665
Averaged Test AUC: 0.8920
Std Test Accurancy: 0.1129
Std Test AUC: 0.0473
------------------------- time cost ------------------------- 547.2599015235901

-------------Round number: 23-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7831
Averaged Test Accurancy: 0.6713
Averaged Test AUC: 0.8992
Std Test Accurancy: 0.1176
Std Test AUC: 0.0512
------------------------- time cost ------------------------- 542.997752904892

-------------Round number: 24-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7864
Averaged Test Accurancy: 0.6881
Averaged Test AUC: 0.9081
Std Test Accurancy: 0.1216
Std Test AUC: 0.0540
------------------------- time cost ------------------------- 551.547899723053

-------------Round number: 25-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7732
Averaged Test Accurancy: 0.6844
Averaged Test AUC: 0.9032
Std Test Accurancy: 0.1223
Std Test AUC: 0.0522
------------------------- time cost ------------------------- 544.2667305469513

-------------Round number: 26-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7672
Averaged Test Accurancy: 0.6881
Averaged Test AUC: 0.9137
Std Test Accurancy: 0.1219
Std Test AUC: 0.0603
------------------------- time cost ------------------------- 542.5480055809021

-------------Round number: 27-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7553
Averaged Test Accurancy: 0.6777
Averaged Test AUC: 0.9089
Std Test Accurancy: 0.1172
Std Test AUC: 0.0547
------------------------- time cost ------------------------- 531.7902414798737

-------------Round number: 28-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7595
Averaged Test Accurancy: 0.6800
Averaged Test AUC: 0.9165
Std Test Accurancy: 0.1171
Std Test AUC: 0.0592
------------------------- time cost ------------------------- 537.552670955658

-------------Round number: 29-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7356
Averaged Test Accurancy: 0.6721
Averaged Test AUC: 0.9164
Std Test Accurancy: 0.1134
Std Test AUC: 0.0593
------------------------- time cost ------------------------- 542.4763703346252

-------------Round number: 30-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7359
Averaged Test Accurancy: 0.6805
Averaged Test AUC: 0.9170
Std Test Accurancy: 0.1193
Std Test AUC: 0.0597
------------------------- time cost ------------------------- 536.6251962184906

-------------Round number: 31-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7172
Averaged Test Accurancy: 0.6685
Averaged Test AUC: 0.9127
Std Test Accurancy: 0.1147
Std Test AUC: 0.0607
------------------------- time cost ------------------------- 541.2523097991943

-------------Round number: 32-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7174
Averaged Test Accurancy: 0.6660
Averaged Test AUC: 0.9113
Std Test Accurancy: 0.1105
Std Test AUC: 0.0580
------------------------- time cost ------------------------- 617.7279732227325

-------------Round number: 33-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7051
Averaged Test Accurancy: 0.6745
Averaged Test AUC: 0.9150
Std Test Accurancy: 0.1244
Std Test AUC: 0.0578
------------------------- time cost ------------------------- 697.4212582111359

-------------Round number: 34-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.7101
Averaged Test Accurancy: 0.6483
Averaged Test AUC: 0.9074
Std Test Accurancy: 0.1070
Std Test AUC: 0.0565
------------------------- time cost ------------------------- 591.1030471324921

-------------Round number: 35-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6845
Averaged Test Accurancy: 0.6610
Averaged Test AUC: 0.9116
Std Test Accurancy: 0.1083
Std Test AUC: 0.0560
------------------------- time cost ------------------------- 603.2557549476624

-------------Round number: 36-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6780
Averaged Test Accurancy: 0.6622
Averaged Test AUC: 0.9100
Std Test Accurancy: 0.1032
Std Test AUC: 0.0563
------------------------- time cost ------------------------- 578.6123204231262

-------------Round number: 37-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6814
Averaged Test Accurancy: 0.6783
Averaged Test AUC: 0.9154
Std Test Accurancy: 0.1177
Std Test AUC: 0.0611
------------------------- time cost ------------------------- 545.5276260375977

-------------Round number: 38-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6624
Averaged Test Accurancy: 0.6764
Averaged Test AUC: 0.9128
Std Test Accurancy: 0.1143
Std Test AUC: 0.0581
------------------------- time cost ------------------------- 569.6946029663086

-------------Round number: 39-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6722
Averaged Test Accurancy: 0.6770
Averaged Test AUC: 0.9154
Std Test Accurancy: 0.1161
Std Test AUC: 0.0574
------------------------- time cost ------------------------- 574.3508577346802

-------------Round number: 40-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6530
Averaged Test Accurancy: 0.6717
Averaged Test AUC: 0.9114
Std Test Accurancy: 0.1108
Std Test AUC: 0.0559
------------------------- time cost ------------------------- 545.4384384155273

-------------Round number: 41-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6610
Averaged Test Accurancy: 0.6787
Averaged Test AUC: 0.9147
Std Test Accurancy: 0.1167
Std Test AUC: 0.0576
------------------------- time cost ------------------------- 535.6674633026123

-------------Round number: 42-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6389
Averaged Test Accurancy: 0.6690
Averaged Test AUC: 0.9055
Std Test Accurancy: 0.0892
Std Test AUC: 0.0473
------------------------- time cost ------------------------- 528.8189158439636

-------------Round number: 43-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6170
Averaged Test Accurancy: 0.6642
Averaged Test AUC: 0.9030
Std Test Accurancy: 0.1063
Std Test AUC: 0.0535
------------------------- time cost ------------------------- 545.2588353157043

-------------Round number: 44-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6135
Averaged Test Accurancy: 0.6652
Averaged Test AUC: 0.9043
Std Test Accurancy: 0.0948
Std Test AUC: 0.0516
------------------------- time cost ------------------------- 538.3474812507629

-------------Round number: 45-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6120
Averaged Test Accurancy: 0.6524
Averaged Test AUC: 0.8981
Std Test Accurancy: 0.1025
Std Test AUC: 0.0494
------------------------- time cost ------------------------- 537.9113690853119

-------------Round number: 46-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6148
Averaged Test Accurancy: 0.6632
Averaged Test AUC: 0.9038
Std Test Accurancy: 0.1032
Std Test AUC: 0.0509
------------------------- time cost ------------------------- 544.608699798584

-------------Round number: 47-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.5945
Averaged Test Accurancy: 0.6563
Averaged Test AUC: 0.8950
Std Test Accurancy: 0.1004
Std Test AUC: 0.0501
------------------------- time cost ------------------------- 536.1709911823273

-------------Round number: 48-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.6074
Averaged Test Accurancy: 0.6504
Averaged Test AUC: 0.8920
Std Test Accurancy: 0.0896
Std Test AUC: 0.0484
------------------------- time cost ------------------------- 533.1077194213867

-------------Round number: 49-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.5786
Averaged Test Accurancy: 0.6451
Averaged Test AUC: 0.8836
Std Test Accurancy: 0.1051
Std Test AUC: 0.0459
------------------------- time cost ------------------------- 498.79675674438477

-------------Round number: 50-------------

Evaluate global model
Client 0 test data size: 673
Client 1 test data size: 1945
Client 2 test data size: 6884
Client 3 test data size: 88
Client 4 test data size: 240
Averaged Train Loss: 0.5977
Averaged Test Accurancy: 0.6465
Averaged Test AUC: 0.8856
Std Test Accurancy: 0.0963
Std Test AUC: 0.0449
------------------------- time cost ------------------------- 506.1146411895752

Best accuracy.
0.6886063072227874

Average time cost per round.
550.0842376422883
File path: ../results/DRnpz_FedAvg_test_0.h5

Average time cost: 28104.06s.
Length:  51
std for best accurancy: 0.0
mean for best accurancy: 0.6886063072227874
All done!

Storage on cuda:0
-------------------------------------------------------------------------------
Total Tensors: 1076063537 	Used Memory: 2.33G
The allocated memory on cuda:0: 2.40G
Memory differs due to the matrix alignment or invisible gradient buffer tensors
-------------------------------------------------------------------------------

Storage on cpu
-------------------------------------------------------------------------------
Total Tensors: 5929 	Used Memory: 23.50K
-------------------------------------------------------------------------------
